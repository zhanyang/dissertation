\chapter{Evaluation}
\label{chap:eval}

This chapter evaluates the performance of \betrfs with
range-rename (\betrfsFour) and \betrfs with range-clone (\betrfsFive),
comparing them with widely used file systems and \betrfsThree.
The evaluation includes both micro and macro benchmarks.

\paragraph{Experimental Setup.}

All experimental results were collected on
a Dell Optiplex 790 with a 4-core 3.40 GHz Intel Core i7-2600 CPU,
4GB RAM,
and a 128 GiB partition (the rest of the disk is not used)
of a 500 GB, 7200 SATA disk with a 4096-byte block size(Seagate Barracuda ST500DM002).
The system runs 64-bit Ubuntu server 14.04.6 on a USB stick to prevent
interference from the root file system.
\betrfsThree and \betrfsFour run on a modified Linux 3.11.10 kernel that
enlarges the size of the kernel stack,
while \betrfsFive and all other file systems run on Linux 4.9.142 kernel.
The evaluation uses ZFS 0.6.5.11 from \url{zfsonlinx.org} and
ext4, Btrfs, XFS and NILFS2 as parts of the Linux kernel.
Each experiment runs a minimum of 5 times and reports the average number.
Error bars indicate (95\%)confidence intervals over all runs.
Similarly, error $\pm$ terms show confidence intervals over all runs.
Unless noted, all benchmarks are cold-cache tests.

We run benchmarks on empty file systems and aged file systems.
We age the file system by emulating user behaviors.
First, we fill the file system with files and directories from the root file
system, roughly taking up 31 GiB space.
Then, we clone the git repository of the Linux kernel with the release tag
``v3.12'' to the home directory in the file system.
Afterwards, we repeat the process of building the kernel and pulling the next
release of the repository
until we build the Linux kernel with the release tag ``v4.20''.
This process takes about 5 days to complete, building the kernel 240 times
(though there are only 29 major releases, there are 7 to 9 release candidates
between two consecutive major releases)
and pulling 397481 git commits.
The directory of the git repository takes up about 3.6 GiB space and
after building the kernel, it takes up about 15 GiB space.
Therefore, after the aging process, the whole file system takes up about 46 GiB
space, about 36\% of the partition size.

\section{Microbenchmarks}
\label{sec:micro}

\subsection{Non-namespace operations}

\newcommand{\addSeqPlot}[1]{
    \addplot[
        discard if not={fs}{#1},
        fill=\pgfkeysvalueof{/fs-colors/#1},
        nodes near coords=\pgfkeysvalueof{/fs-names/#1},
    ]
    plot[
        error bars/.cd,
        y dir=both, y explicit,
    ]
    table[
        x=op,
        y=median,
        y error plus expr=\thisrow{ci},
        y error minus expr=\thisrow{ci},
    ]
    {./data/seq_io.csv};
}

\newcommand{\addSeqPlotAged}[1]{
    \addplot[
        discard if not={fs}{#1},
        fill=\pgfkeysvalueof{/fs-colors/#1},
        nodes near coords=\pgfkeysvalueof{/fs-names/#1},
    ]
    plot[
        error bars/.cd,
        y dir=both, y explicit,
    ]
    table[
        x=op,
        y=median,
        y error plus expr=\thisrow{ci},
        y error minus expr=\thisrow{ci},
    ]
    {./data/seq_io_aged.csv};
}

\begin{figure}[t]
    \begin{subfigure}{\textwidth}
        \centering
        \begin{tikzpicture}[yscale=0.95, xscale=0.95]
            \begin{axis}[
                    ybar,
                    ymin=0,
                    ylabel={Bandwidth (MiB/sec)},
                    ymajorgrids=true,
                    symbolic x coords={seq.write,seq.read},
                    xtick={seq.write,seq.read},
                    xticklabels={write,read},
                    enlarge x limits=0.5,
                    visualization depends on=y \as \rawy,
                    xtick pos=right,
                    major tick length=0in,
                    xticklabel pos=right,
                    nodes near coords style={font=\small,anchor=east,rotate=90,xshift=-\pgfplotsunitylength*\rawy,},
                    height=.5\linewidth,
                    width=\linewidth,
                ]
                \addSeqPlot{ext4};
                \addSeqPlot{btrfs};
                \addSeqPlot{xfs};
                \addSeqPlot{zfs};
                \addSeqPlot{nilfs2};
                \addSeqPlot{betrfs3};
                \addSeqPlot{betrfs4};
                \addSeqPlot{betrfs5};
            \end{axis}
        \end{tikzpicture}
        \caption{\label{subfig:seq_io}Benchmarking on empty file systems.}
    \end{subfigure}
    \begin{subfigure}{\textwidth}
        \centering
        \begin{tikzpicture}[yscale=0.95, xscale=0.95]
            \begin{axis}[
                    ybar,
                    ymin=0,
                    ylabel={Bandwidth (MiB/sec)},
                    ymajorgrids=true,
                    symbolic x coords={seq.write,seq.read},
                    xtick={seq.write,seq.read},
                    xticklabels={write,read},
                    enlarge x limits=0.5,
                    visualization depends on=y \as \rawy,
                    xtick pos=right,
                    major tick length=0in,
                    xticklabel pos=right,
                    nodes near coords style={font=\small,anchor=east,rotate=90,xshift=-\pgfplotsunitylength*\rawy,},
                    height=.5\linewidth,
                    width=\linewidth,
                ]
                \addSeqPlotAged{ext4};
            \end{axis}
        \end{tikzpicture}
        \caption{\label{subfig:seq_io_aged}Benchmarking on aged file systems.}
    \end{subfigure}
    \caption[Sequential-write and sequential-read benchmark]{\label{fig:seq_io}
        Bandwidth to sequentially read and write a 10 GiB file (higher is better).}
\end{figure}

\newcolumntype{.}{D{.}{.}{-1}}

\begin{table}[t]
    \begin{subtable}[b]{.5\textwidth}
    \centering
        \begin{tabular}{l|.@{${}\pm{}$}.}
        \hline
        File system & \multicolumn{2}{c}{random write (sec)} \\
        \hline
        \hline
        \input{./data/rand_io.csv}
        \hline
        \end{tabular}
        \caption{\label{subtab:rand_io}Benchmarking on empty file systems.}
    \end{subtable}
    \begin{subtable}[b]{.5\textwidth}
    \centering
        \begin{tabular}{l|.@{${}\pm{}$}.}
        \hline
        File system & \multicolumn{2}{c}{random write (sec)} \\
        \hline
        \hline
        \input{./data/rand_io_aged.csv}
        \hline
        \end{tabular}
        \caption{\label{subtab:rand_io_aged}Benchmarking on aged file systems.}
    \end{subtable}
    \caption[Random-write benchmark]{\label{tab:rand_io}
        Time to perform 256K (262,144) 4-Byte random writes one a 10GiB file (1 MiB total IO, lower is better).}
\end{table}

\begin{table}[t]
    \begin{subtable}{\textwidth}
        \centering
        \begin{tabular}{l|.@{${}\pm{}$}..@{${}\pm{}$}..@{${}\pm{}$}.}
        \hline
        File system & \multicolumn{2}{c}{grep (sec)} & \multicolumn{2}{c}{find (sec)} & \multicolumn{2}{c}{delete (sec)} \\
        \hline
        \hline
        \input{./data/dir_ops.csv}
        \hline
        \end{tabular}
        \caption{\label{subtab:dir_ops}Benchmarking on empty file systems.}
    \end{subtable}
    \begin{subtable}{\textwidth}
        \centering
        \begin{tabular}{l|.@{${}\pm{}$}..@{${}\pm{}$}..@{${}\pm{}$}.}
        \hline
        File system & \multicolumn{2}{c}{grep (sec)} & \multicolumn{2}{c}{find (sec)} & \multicolumn{2}{c}{delete (sec)} \\
        \hline
        \hline
        \input{./data/dir_ops_aged.csv}
        \hline
        \end{tabular}
        \caption{\label{subtab:dir_ops_aged}Benchmarking on aged file systems.}
    \end{subtable}
    \caption[Directory operation benchmark]{\label{tab:dir_ops}
        Time to perform recursive grep, find and delete of the Linux source directory (lower is better).}
\end{table}

\newcommand{\addTokubenchPlot}[1]
{
    \addplot[
        color=\pgfkeysvalueof{/fs-colors/#1},
        line width=0.75pt,
        mark=\pgfkeysvalueof{/fs-marks/#1},
    ]
    plot[
    ]
    table[
    ]
    {./data/toku/#1.csv};
    \addlegendentry{\pgfkeysvalueof{/fs-names/#1}}
}

\newcommand{\addTokubenchPlotAged}[1]
{
    \addplot[
        color=\pgfkeysvalueof{/fs-colors/#1},
        line width=0.75pt,
        mark=\pgfkeysvalueof{/fs-marks/#1},
    ]
    plot[
    ]
    table[
    ]
    {./data/toku_aged/#1.csv};
    \addlegendentry{\pgfkeysvalueof{/fs-names/#1}}
}

\begin{figure}[t]
    \begin{subfigure}{\textwidth}
        \centering
        \begin{tikzpicture}[yscale=0.95, xscale=0.95]
            \begin{axis}[
                    xlabel={Files created},
                    ylabel={Throughput (files/sec)},
                    xmin=0,
                    xmax=3000000,
                    ymin=10,
                    ymax=50000,
                    mark repeat=10,
                    ytick={10000,20000,30000,40000,50000},
                    yticklabels={10k,20k,30k,40k,50k},
                    xtick={0,1000000,2000000,3000000},
                    xticklabels={0,1M,2M,3M},
                    grid=major,
                    scaled x ticks=false,
                    scaled y ticks=false,
                    legend columns=4,
                    legend cell align=left,
                    transpose legend,
                    height=.5\linewidth,
                    width=\linewidth,
                ]
                \addTokubenchPlot{ext4};
                \addTokubenchPlot{btrfs};
                \addTokubenchPlot{xfs};
                \addTokubenchPlot{zfs};
                \addTokubenchPlot{nilfs2};
                \addTokubenchPlot{betrfs3};
                \addTokubenchPlot{betrfs4};
                \addTokubenchPlot{betrfs5};
            \end{axis}
        \end{tikzpicture}
        \caption{\label{subfig:toku}Benchmarking on empty file systems.}
    \end{subfigure}
    \begin{subfigure}{\textwidth}
        \centering
        \begin{tikzpicture}[yscale=0.95, xscale=0.95]
            \begin{axis}[
                    xlabel={Files created},
                    ylabel={Throughput (files/sec)},
                    xmin=0,
                    xmax=3000000,
                    ymin=10,
                    ymax=50000,
                    mark repeat=10,
                    ytick={10000,20000,30000,40000,50000},
                    yticklabels={10k,20k,30k,40k,50k},
                    xtick={0,1000000,2000000,3000000},
                    xticklabels={0,1M,2M,3M},
                    grid=major,
                    scaled x ticks=false,
                    scaled y ticks=false,
                    legend columns=4,
                    legend cell align=left,
                    transpose legend,
                    height=.5\linewidth,
                    width=\linewidth,
                ]
                \addTokubenchPlotAged{ext4};
            \end{axis}
        \end{tikzpicture}
        \caption{\label{subfig:toku_aged}Benchmarking on aged file systems.}
    \end{subfigure}
    \caption[TokuBench benchmark]{\label{fig:toku}
        Cumulative file creation throughput during the Tokubench benchmark (higher is better).}
\end{figure}

\newcommand{\addGitPlot}[1]{
    \addplot[
        discard if not={fs}{#1},
        fill=\pgfkeysvalueof{/fs-colors/#1},
        nodes near coords=\pgfkeysvalueof{/fs-names/#1},
    ]
    plot[
        error bars/.cd,
        y dir=both, y explicit,
    ]
    table[
        x=op,
        y=median,
        y error plus expr=\thisrow{max}-\thisrow{median},
        y error minus expr=\thisrow{median}-\thisrow{min},
    ]
    {./data/git.csv};
}

\begin{figure}[t]
    \begin{tikzpicture}[yscale=0.95, xscale=0.95]
        \begin{axis}[
                ybar,
                ymin=0,
                ylabel={Time (sec)},
                ymajorgrids=true,
                symbolic x coords={clone, diff},
                xticklabels={git clone,git diff},
                xtick={clone,diff},
                enlarge x limits=0.5,
                xtick pos=right,
                major tick length=0in,
                xticklabel pos=right,
                visualization depends on=y \as \rawy,
                nodes near coords style={font=\large,anchor=east,rotate=90,xshift=-\pgfplotsunitylength*\rawy,},
                height=.6\linewidth,
                width=\linewidth,
            ]
            \addGitPlot{ext4};
            \addGitPlot{btrfs};
            \addGitPlot{xfs};
            \addGitPlot{zfs};
            \addGitPlot{nilfs2};
            \addGitPlot{betrfs4};
            \addGitPlot{betrfs5};
        \end{axis}
    \end{tikzpicture}
    \caption[Git benchmark]{\label{fig:git}
        Latency of ``git clone'' and ``git diff'' (lower is better).}
\end{figure}

\newcommand{\addTarPlot}[1]{
    \addplot[
        discard if not={fs}{#1},
        fill=\pgfkeysvalueof{/fs-colors/#1},
        nodes near coords=\pgfkeysvalueof{/fs-names/#1},
    ]
    plot[
        error bars/.cd,
        y dir=both, y explicit,
    ]
    table[
        x=op,
        y=median,
        y error plus expr=\thisrow{max}-\thisrow{median},
        y error minus expr=\thisrow{median}-\thisrow{min},
    ]
    {./data/tar.csv};
}

\begin{figure}[t]
    \begin{tikzpicture}[yscale=0.95, xscale=0.95]
        \begin{axis}[
                ybar,
                ymin=0,
                ylabel={Time (sec)},
                ymajorgrids=true,
                symbolic x coords={untar,tar},
                xtick={untar,tar},
                enlarge x limits=0.5,
                xtick pos=right,
                major tick length=0in,
                xticklabel pos=right,
                visualization depends on=y \as \rawy,
                nodes near coords style={font=\large,anchor=east,rotate=90,xshift=-10*\pgfplotsunitylength*\rawy,},
                height=.6\linewidth,
                width=\linewidth,
            ]
            \addTarPlot{ext4};
            \addTarPlot{btrfs};
            \addTarPlot{xfs};
            \addTarPlot{zfs};
            \addTarPlot{nilfs2};
            \addTarPlot{betrfs4};
            \addTarPlot{betrfs5};
        \end{axis}
    \end{tikzpicture}
    \caption[Tar benchmark]{\label{fig:tar}
        Latency to untar and tar the Liinux-3.11.10 source directory (lower is better).}
\end{figure}

\newcommand{\addRsyncPlot}[1]{
    \addplot[
        discard if not={fs}{#1},
        fill=\pgfkeysvalueof{/fs-colors/#1},
        nodes near coords=\pgfkeysvalueof{/fs-names/#1},
    ]
    plot[
        error bars/.cd,
        y dir=both, y explicit,
    ]
    table[
        x=inplace,
        y=median,
        y error plus expr=\thisrow{max}-\thisrow{median},
        y error minus expr=\thisrow{median}-\thisrow{min},
    ]
    {./data/rsync.csv};
}

\begin{figure}[t]
    \begin{tikzpicture}[yscale=0.95, xscale=0.95]
        \begin{axis}[
                ybar,
                ymin=0,
                ylabel={Bandwidth (MB/sec)},
                ymajorgrids=true,
                symbolic x coords={yes,no},
                xtick={yes,no},
                xticklabels={\large{\texttt{--in-place}},\large{rename}},
                enlarge x limits=0.5,
                xtick pos=right,
                major tick length=0in,
                xticklabel pos=right,
                visualization depends on=y \as \rawy,
                nodes near coords style={font=\large,anchor=east,rotate=90,xshift=-10*\pgfplotsunitylength*\rawy,},
                height=.6\linewidth,
                width=\linewidth,
            ]
        \addRsyncPlot{ext4};
        \addRsyncPlot{btrfs};
        \addRsyncPlot{xfs};
        \addRsyncPlot{zfs};
        \addRsyncPlot{nilfs2};
        \addRsyncPlot{betrfs4};
        \addRsyncPlot{betrfs5};
        \end{axis}
    \end{tikzpicture}
    \caption[Rsync benchmark]{\label{fig:rsync}
        Throughput of using rsync to clone the Linux-3.11.10 source directory (higher is better).}
\end{figure}

\newcommand{\addIMAPPlot}[1]{
    \addplot[
        discard if not={fs}{#1},
        fill=\pgfkeysvalueof{/fs-colors/#1},
        nodes near coords=\pgfkeysvalueof{/fs-names/#1},
    ]
    plot[
        error bars/.cd,
        y dir=both, y explicit,
    ]
    table[
        x=fs,
        y=median,
        y error plus expr=\thisrow{max}-\thisrow{median},
        y error minus expr=\thisrow{median}-\thisrow{min},
    ]
    {./data/imap.csv};
}

\begin{figure}[t]
    \begin{tikzpicture}[yscale=0.95, xscale=0.95]
        \begin{axis}[
                ybar=0pt,
                /pgf/bar shift=0pt,
                ymin=0,
                ylabel={Throughput (op/s)},
                ymajorgrids=true,
                symbolic x coords={ext4,btrfs,xfs,zfs,nilfs2,betrfs4,betrfs5,betrfs5-clone},
                xticklabels={},
                xtick pos=right,
                major tick length=0in,
                xticklabel pos=right,
                visualization depends on=y \as \rawy,
                nodes near coords style={font=\large,anchor=east,rotate=90,xshift=-\pgfplotsunitylength*\rawy,},
                height=.6\linewidth,
                width=\linewidth,
            ]
            \addIMAPPlot{ext4};
            \addIMAPPlot{btrfs};
            \addIMAPPlot{xfs};
            \addIMAPPlot{zfs};
            \addIMAPPlot{nilfs2};
            \addIMAPPlot{betrfs4};
            \addIMAPPlot{betrfs5};
        \end{axis}
    \end{tikzpicture}
    \caption[Mailserver benchmark]{\label{fig:imap}
        Throughput of the dovecot mailserver (higher is better).}
\end{figure}

\paragraph{Sequential writes and reads.}

We measure the throughput of sequentially writing and reading a file.
This benchmark first writes a 10GiB file, 40MiB at a time, with a
\texttt{fsync} to flush the file to the disk.
Then, after clearing the kernel page cache, the benchmark reads the file from
the disk.

Figure~\ref{subfig:seq_io} shows the results of running the benchmark on empty
file systems, in which the 10GiB file is put directly under the root directory.
Ext4, Btrfs, XFS performs sequential
writes close to disk bandwidth, while \betrfsFive, similar to NILFS2, is about
6.5\% slower than the fastest file system.
The performance increase of \betrfsFive from \betrfsFour is from preferential
splitting (Section~\ref{sec:rcimp}),
which creates a pivot matching the maximum file data key at the
beginning of the workload, avoiding further node relifting in subsequent node
splits as the file grows.
For sequential reads, Ext4, Btrfs, XFS run at disk bandwidth, while \betrfsFive
is 19.1\% slower than the fastest file system, which is close to \betrfsFour
and NILFS2.
\betrfs reads a leaf, which is about 4 MiB in size, each time, while
extent-based file systems can have extents whose size is more than 100 MiB.
Thus, sequential reads results in more (and smaller) IOs on \betrfs.

Figure~\ref{subfig:seq_io_aged} shows the results of running the benchmark on
the ag4ed file systems, in whcih the 10GiB file is put under the aged git
repository.

\paragraph{Random writes.}

We then measure the performance of random writes on the file generated by the
sequential write benchmark.
The benchmark issues 256K (262,144) 4-Byte overwrites (in total 1 MiB data) at
random offsets within the 10GiB file, followed by an \texttt{fsync}.

Table~\ref{subtab:rand_io} shows the results of running the benchmark
on empty file systems.
Because \betrfs performs upserts, which doesn't read the old data, for random
writes, performing the 1MiB random writes only takes less than 4 seconds on
\betrfsFour and \betrfsFive.
However, it takes at least 2000 seconds on other file systems, which is
more than 500 times slower.
The performance improvement from \betrfsThree comes from some code optimization
in \fti.

Table~\ref{subtab:rand_io_aged} shows the results of running the benchmark on
aged file systems.

\paragraph{Directory operations.}
Next, we measure three common directory operations,
\texttt{grep}, \texttt{find}, and \texttt{delete}.
The grep benchmark measures the time to grep keyword cpu\_to\_be64 on th
Linux source diretory.
The find benchmark measures the time to find file wait.c on the same direcotry.
And the delete benchmark measures the time to recursively delete the directory
with ``rm -rf''.

Table~\ref{subtab:dir_ops} shows the results of running the benchmark on emtpy
file systems.
We copy the Linux 3.11.10 source directory to the file system and then
perform operations on that directory.
Because full-path indexing ensures locality in \betrfs, \texttt{find} and
\texttt{grep} on \betrfsFour and \betrfsFive are more than two times faster than
other file systems.
Recursive delete is implemented by range-delete messages in \betrfsFour and
\goto messages in \betrfsFive, both shows comparable performance against other
file systems.

Table~\ref{subtab:dir_ops_aged} shows the results of running the benchmark on
aged file systems.
Before benchmarking, we use ``make clean'' to remove files generated by kenerl
building in the aged git repository.
Then, we measure the performance of operations on the directory of the aged
git repository.

\paragraph{TokuBench.}

TokuBench~\citep{tokufs} is a small-write-intensive benchmark that creates 3
million 200-Byte files in a balanced tree directory.
The benchmark first creates the balanced tree directory with a fanout of 128,
i.e., each directory has at most 128 directories or 128 files.
Then, it creates 4 threads.
Each thread iterates over the leaf directories, creating one file at a time.
The benchmark reports the cumulative throughput of the file creation each time
when 10,000 files are created.

Figure~\ref{subfig:toku} shows the results of running Tokubench on empty file
systems.
Because Tokubench excercises small, random writes,
\betrfsFour and \betrfsFive are significantly faster than ext4, Btrfs and XFS.
Also, \betrfsFour and \betrfsFive don't have the sudden performance drop that
occurs in \betrfsThree (described in Section~\ref{sec:rpi}).
\betrfsFive performs better than \betrfsFour because preferential splitting
also avoids further relifting in the benchmark.
We expect NILFS to perform better than \betrfsFive in TokuBench that creates
more files,
because as a log-structured file system, NILFS2 would have stable performance
until the log (disk) is full.

Figure~\ref{subfig:toku_aged} shows the results of running Tokubench on aged
file systems.
In this case, we run the benchmark in the directory of the aged git repository.

\subsection{Namespace operations}


\section{Macrobenchmarks}
\label{sec:macro}

We then measure the performance of file systems on four canonical applications.

\paragraph{Git.}

The git benchmark first measures the latency of finishing ``git clone'' that
clones a local copy of the linux source repository,
then measures the latency of finishing ``git diff'' that generates a patch
between two tags in the repository, the ``v4.7'' and ``v4.14'' tags.

Figure~\ref{fig:git} shows the results.
The ``git clone'' benchmark performs a mixture sequential writes and file
creations.
\betrfsFour and \betrfsFive are slightly slower than ext4 and Btrfs mainly
because they have slower sequential writes.
The ``git diff'' benchmark traverses the directory and reads the deltas from git
objects.
\betrfsFour and \betrfsFive are among the fastest file systems because of good
locality in directory traversals.

\paragraph{Tar.}

The tar benchmark measures the latency of untar and tar.
The benchmark first copies a Linux-3.11.10 source tar ball to the file systems.
Then, it measures the time to untar the tar ball, which writes a Linux-3.11.10
source directory.
At last, it measures the time to generate a tar ball from the newly created
Linux-3.11.10 source directory.

Figure~\ref{fig:tar} shows the result.
Untaring consists sequentially reading the tar ball and file creations.
\betrfsFour and \betrfsFive are only slightly slower than Btrfs.
Taring traverse the directory and sequentially writes the tar ball.
\betrfsFour and \betrfsFive are the fastest file system in the tar benchmark.

\paragraph{Rsync.}

The rsync benchmark first creates a Linux-3.11.10 source directory in the file
system, then uses rsync to create a copy of the directory.
This benchmark runs twice on each file system, one with the ``in-place'' flags
and the other without the flag.
Without the flag, rsync would first creates temporary files and rename them to
be final files, while with the flag, rsync would creates files in place.

Figure~\ref{fig:rsync} shows the results.
\betrfsFour and \betrfsFive have much higher throughput than other file system
because part of the job is to traverse the old directory.

\paragraph{Mailserver.}

The mailserver benchmarks measures the througput of the dovecot mailserver on
different file systems.
The mailserver is configured with Maildir option, therefore, each mail is a
file.
Initially, it has 10 boxes, each with 1000 mails.
Then, the benchmark creates four threads that interact with the mailserver and
measure the throughput.
Each threads performs 50\% reads and 50\%write, writes are randomly chosen from
creating a new mail, deleting an existing mail and changing the flag of an
existing mail with equal probabilities.

Figure~\ref{fig:imap} shows the results.
Because the benchmark performs random small writes, \betrfsFour and \betrfsFive
are only slightly slower than NILFS2.

\section{Summary}
